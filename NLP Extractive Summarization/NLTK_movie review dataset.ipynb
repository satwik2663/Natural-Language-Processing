{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "## movie review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "# list of categories \n",
    "print(movie_reviews.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt']\n",
      "number of the documents in neg : 1000\n",
      "['pos/cv000_29590.txt', 'pos/cv001_18431.txt', 'pos/cv002_15918.txt']\n",
      "number of the documents in pos : 1000\n"
     ]
    }
   ],
   "source": [
    "for category in movie_reviews.categories():\n",
    "    print(movie_reviews.fileids(category)[:3]) # sample of some of the file names in the various doocuments(['neg', 'pos'])\n",
    "    print(\"number of the documents in \" + str(category) + \" : \"  + str(len(movie_reviews.fileids(category))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583820\n"
     ]
    }
   ],
   "source": [
    "# list of count of the words, \n",
    "words = []\n",
    "for word in movie_reviews.words():\n",
    "    #if word not in set(stopwords.words('english')): # with the removal of stop words\n",
    "    words.append(word.lower())\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583820\n",
      "1331109\n"
     ]
    }
   ],
   "source": [
    "# Removing special charaters\n",
    "words = list(re.sub('[^a-zA-Z]','', word) for word in words )\n",
    "print(len(words))\n",
    "clean_word = []\n",
    "for word in words:\n",
    "    if word != '':\n",
    "        clean_word.append(word)\n",
    "print(len(clean_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_word = [word for word in clean_word if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702383"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now taking the frequency distribution of the filtered_words\n",
    "freq_filtered_words = nltk.FreqDist(filtered_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38809"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting top 3000 words out of 38809\n",
    "top_3000_words = list(freq_filtered_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot', 'two', 'teen', 'couples', 'go']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3000_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now seeing the top 3000 words in every document to create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "def find_features(file_id):\n",
    "    #print(file_id)\n",
    "    words = list(set(movie_reviews.words(file_id)))\n",
    "    #print(words)\n",
    "    features = {}\n",
    "    for word in top_3000_words:\n",
    "        if word in words:\n",
    "            features[word] = True\n",
    "        else:\n",
    "            features[word] = False\n",
    "    features_list.append(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categories in movie_reviews.categories():\n",
    "    for file_id in movie_reviews.fileids(categories):\n",
    "        #print(categories)\n",
    "        find_features(file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>able</th>\n",
       "      <th>abo</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>accentuate</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuppie</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombified</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abc  aberdeen   able    abo  absent  absolutely  accent  accentuate  \\\n",
       "0  False     False  False  False   False       False   False       False   \n",
       "1  False     False  False  False   False       False   False       False   \n",
       "2  False     False  False  False   False       False   False       False   \n",
       "3  False     False   True  False   False       False   False       False   \n",
       "4  False     False  False   True   False       False   False       False   \n",
       "\n",
       "   accident  accidentally   ...     young  youngsters  youth  yuppie   zero  \\\n",
       "0      True         False   ...     False       False  False   False  False   \n",
       "1     False         False   ...     False       False  False   False  False   \n",
       "2     False         False   ...      True       False  False   False  False   \n",
       "3     False          True   ...     False       False  False   False  False   \n",
       "4      True         False   ...     False       False  False   False  False   \n",
       "\n",
       "   zombified   zone  zoologist  zwigoff  zzzzzzz  \n",
       "0      False  False      False    False    False  \n",
       "1      False  False      False    False    False  \n",
       "2      False  False      False    False    False  \n",
       "3      False  False      False    False    False  \n",
       "4      False  False      False    False    False  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data frame to the format in which nltk.train would work : https://stackoverflow.com/questions/29337714/how-to-run-naive-bayes-from-nltk-with-python-pandas\n",
    "# featuresets should be of the form [(featureset, label)] , where the featureset variable is a dict\n",
    "train = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "for dict in train[:1000]:\n",
    "    train_list.append((dict,'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict in train[1000:]:\n",
    "    train_list.append((dict,'pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "training_set = train_list[:1800]\n",
    "\n",
    "# test data\n",
    "testing_set = train_list[1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 81.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  annual = True              pos : neg    =     11.2 : 1.0\n",
      "                 idiotic = True              neg : pos    =     10.7 : 1.0\n",
      "                 frances = True              pos : neg    =      9.6 : 1.0\n",
      "                   sucks = True              neg : pos    =      8.5 : 1.0\n",
      "                bothered = True              neg : pos    =      7.7 : 1.0\n",
      "                     ugh = True              neg : pos    =      7.7 : 1.0\n",
      "                 cunning = True              pos : neg    =      7.1 : 1.0\n",
      "                  turkey = True              neg : pos    =      7.0 : 1.0\n",
      "           unimaginative = True              neg : pos    =      6.7 : 1.0\n",
      "                    lame = True              neg : pos    =      6.4 : 1.0\n",
      "                  regard = True              pos : neg    =      6.2 : 1.0\n",
      "                 singers = True              pos : neg    =      6.2 : 1.0\n",
      "                 unravel = True              pos : neg    =      6.2 : 1.0\n",
      "              undercover = True              neg : pos    =      6.2 : 1.0\n",
      "                  sexist = True              neg : pos    =      6.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pickle file to save the classfier\n",
    "save_classifier = open('mov_rev_naivebayes.pickle','wb')\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pickle file\n",
    "classifier_f = open('mov_rev_naivebayes.pickle','rb')\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 81.5\n",
      "Most Informative Features\n",
      "                  annual = True              pos : neg    =     11.2 : 1.0\n",
      "                 idiotic = True              neg : pos    =     10.7 : 1.0\n",
      "                 frances = True              pos : neg    =      9.6 : 1.0\n",
      "                   sucks = True              neg : pos    =      8.5 : 1.0\n",
      "                bothered = True              neg : pos    =      7.7 : 1.0\n",
      "                     ugh = True              neg : pos    =      7.7 : 1.0\n",
      "                 cunning = True              pos : neg    =      7.1 : 1.0\n",
      "                  turkey = True              neg : pos    =      7.0 : 1.0\n",
      "           unimaginative = True              neg : pos    =      6.7 : 1.0\n",
      "                    lame = True              neg : pos    =      6.4 : 1.0\n",
      "                  regard = True              pos : neg    =      6.2 : 1.0\n",
      "                 singers = True              pos : neg    =      6.2 : 1.0\n",
      "                 unravel = True              pos : neg    =      6.2 : 1.0\n",
      "              undercover = True              neg : pos    =      6.2 : 1.0\n",
      "                  sexist = True              neg : pos    =      6.1 : 1.0\n",
      "MNB_classifier accuracy percent: 81.5\n",
      "BernoulliNB_classifier accuracy percent: 82.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 77.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 80.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_classifier accuracy percent: 16.5\n",
      "LinearSVC_classifier accuracy percent: 74.5\n",
      "NuSVC_classifier accuracy percent: 77.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using other method to train\n",
    "df_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>able</th>\n",
       "      <th>abo</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>accentuate</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuppie</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombified</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abc  aberdeen   able    abo  absent  absolutely  accent  accentuate  \\\n",
       "0  False     False  False  False   False       False   False       False   \n",
       "1  False     False  False  False   False       False   False       False   \n",
       "2  False     False  False  False   False       False   False       False   \n",
       "3  False     False   True  False   False       False   False       False   \n",
       "4  False     False  False   True   False       False   False       False   \n",
       "\n",
       "   accident  accidentally   ...     young  youngsters  youth  yuppie   zero  \\\n",
       "0      True         False   ...     False       False  False   False  False   \n",
       "1     False         False   ...     False       False  False   False  False   \n",
       "2     False         False   ...      True       False  False   False  False   \n",
       "3     False          True   ...     False       False  False   False  False   \n",
       "4      True         False   ...     False       False  False   False  False   \n",
       "\n",
       "   zombified   zone  zoologist  zwigoff  zzzzzzz  \n",
       "0      False  False      False    False    False  \n",
       "1      False  False      False    False    False  \n",
       "2      False  False      False    False    False  \n",
       "3      False  False      False    False    False  \n",
       "4      False  False      False    False    False  \n",
       "\n",
       "[5 rows x 3000 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = []\n",
    "for i in range(0,2000):\n",
    "    if i < 1000:\n",
    "        tag.append('neg')\n",
    "    else:\n",
    "        tag.append('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['tag'] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, testing = train_test_split(df_data, test_size = .25, stratify = df_data['tag'], random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = df_data[:1900]\n",
    "testing = df_data[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.copy()\n",
    "y_train = training['tag']\n",
    "training.drop(columns = ['tag'], inplace = True)\n",
    "X_train = training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = testing.copy()\n",
    "y_test = testing['tag']\n",
    "testing.drop(columns = ['tag'], inplace = True)\n",
    "X_test = testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier accuracy percent: 80.0\n",
      "BernoulliNB accuracy percent: 80.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy percent: 83.0\n",
      "Sto. grad descent accuracy percent: 81.0\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = MultinomialNB()\n",
    "MNB_classifier.fit(X_train, y_train)\n",
    "y_pred_mnb = MNB_classifier.predict(X_test)\n",
    "print(\"MNB_classifier accuracy percent:\", accuracy_score(y_test, y_pred_mnb) * 100)\n",
    "\n",
    "BNB_classifier = BernoulliNB()\n",
    "BNB_classifier.fit(X_train, y_train)\n",
    "y_pred_bnb = BNB_classifier.predict(X_test)\n",
    "print(\"BernoulliNB accuracy percent:\", accuracy_score(y_test, y_pred_bnb) * 100)\n",
    "\n",
    "LogisticRegression_classifier = LogisticRegression()\n",
    "LogisticRegression_classifier.fit(X_train, y_train)\n",
    "y_pred_lr = LogisticRegression_classifier.predict(X_test)\n",
    "print(\"Logistic Regression accuracy percent:\", accuracy_score(y_test, y_pred_lr) * 100)\n",
    "\n",
    "SGDClassifier_classifier = SGDClassifier()\n",
    "SGDClassifier_classifier.fit(X_train, y_train)\n",
    "y_pred_sgd = SGDClassifier_classifier.predict(X_test)\n",
    "print(\"Sto. grad descent accuracy percent:\", accuracy_score(y_test, y_pred_sgd) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
