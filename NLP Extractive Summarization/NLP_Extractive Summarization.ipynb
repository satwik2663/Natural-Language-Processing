{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import bs4 as BeautifulSoup\n",
    "import urllib.request \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    #reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    #creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "    #print(frequency_table)\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        print(\"sentence\", sentence)\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        print(\"sentence_wordcount\",sentence_wordcount)\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            print(\"word_weight\",word_weight)\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                print(\"sentence_wordcount_without_stop_words\",sentence_wordcount_without_stop_words)\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                    print(\"sentence wiight\", sentence_weight[sentence[:7]])\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words\n",
    "\n",
    "       \n",
    "    #print(sentence_weight)\n",
    "    return sentence_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    #calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    #getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "\n",
    "    return article_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91880\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91880\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER TEXT HERE. MY NAME IS SATWIK\n",
      "=======================================================\n",
      "{'enter': 1, 'text': 1, '.': 1, 'MY': 1, 'name': 1, 'IS': 1, 'satwik': 1}========================================================\n",
      "sentences\n",
      "['ENTER TEXT HERE.', 'MY NAME IS SATWIK']\n",
      "========================================================\n",
      "sentence ENTER TEXT HERE.\n",
      "sentence_wordcount 4\n",
      "word_weight enter\n",
      "sentence_wordcount_without_stop_words 1\n",
      "word_weight text\n",
      "sentence_wordcount_without_stop_words 2\n",
      "sentence wiight 2\n",
      "word_weight .\n",
      "sentence_wordcount_without_stop_words 3\n",
      "sentence wiight 3\n",
      "word_weight MY\n",
      "word_weight name\n",
      "word_weight IS\n",
      "word_weight satwik\n",
      "sentence MY NAME IS SATWIK\n",
      "sentence_wordcount 4\n",
      "word_weight enter\n",
      "word_weight text\n",
      "word_weight .\n",
      "word_weight MY\n",
      "word_weight name\n",
      "sentence_wordcount_without_stop_words 1\n",
      "word_weight IS\n",
      "word_weight satwik\n",
      "sentence_wordcount_without_stop_words 2\n",
      "sentence wiight 2\n",
      "sentence_scores\n",
      "{'ENTER T': 1.0, 'MY NAME': 1.0}\n",
      "========================================================\n",
      "threshold\n",
      "1.0\n",
      "========================================================\n",
      "========================================================\n",
      "-------------\n",
      " ENTER TEXT HERE. MY NAME IS SATWIK\n"
     ]
    }
   ],
   "source": [
    "def _run_article_summary(article):\n",
    "    \n",
    "    print(article)\n",
    "    print('=======================================================')\n",
    "    #creating a dictionary for the word frequency table\n",
    "    frequency_table = _create_dictionary_table(article)\n",
    "    print(frequency_table, end = '')\n",
    "    print('========================================================')\n",
    "    \n",
    "    #tokenizing the sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "    print('sentences')\n",
    "    print(sentences)\n",
    "    print('========================================================')\n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "    print('sentence_scores')\n",
    "    print(sentence_scores)\n",
    "    print('========================================================')\n",
    "    \n",
    "    #getting the threshold\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "    print('threshold')\n",
    "    print(threshold)\n",
    "    print('========================================================')\n",
    "    \n",
    "    #producing the summary\n",
    "    article_summary = _get_article_summary(sentences, sentence_scores, 1 * threshold)\n",
    "    print('========================================================')\n",
    "    return article_summary\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #print(article_content)\n",
    "    article_content = \"ENTER TEXT HERE. MY NAME IS SATWIK\"\n",
    "    summary_results = _run_article_summary(article_content)\n",
    "    print('-------------')\n",
    "    print(summary_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
